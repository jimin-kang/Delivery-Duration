{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've prepped the data, let's build a model to predict delivery duration.\n",
    "\n",
    "We will experiment with various regression algorithms. For each algorithm, we will tune relevant hyperparameters to maximize algorithm performance. Then, we will compare performance across models.\n",
    "\n",
    "We will build models using the following regression algorithms:\n",
    "- Linear (Lasso) Regression\n",
    "- Support Vector Regression\n",
    "- Random Forest Regression\n",
    "- Gradient Boosted Regression\n",
    "\n",
    "We will evaluate these models on Root Mean Squared Error (RMSE), as that will allow us to express the errors of the predictions in seconds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load cleaned train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# ensures notebook automatically receives updates from .py files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>actual_delivery_time</th>\n",
       "      <th>store_id</th>\n",
       "      <th>store_primary_category</th>\n",
       "      <th>order_protocol</th>\n",
       "      <th>total_items</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>num_distinct_items</th>\n",
       "      <th>min_item_price</th>\n",
       "      <th>...</th>\n",
       "      <th>total_onshift_dashers</th>\n",
       "      <th>total_busy_dashers</th>\n",
       "      <th>total_outstanding_orders</th>\n",
       "      <th>estimated_order_place_duration</th>\n",
       "      <th>estimated_store_to_consumer_driving_duration</th>\n",
       "      <th>seconds_to_delivery</th>\n",
       "      <th>store_id_freq</th>\n",
       "      <th>store_category_type</th>\n",
       "      <th>item_price_range</th>\n",
       "      <th>hour_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-02-17 22:10:38+00:00</td>\n",
       "      <td>2015-02-17 22:40:27+00:00</td>\n",
       "      <td>2963</td>\n",
       "      <td>american</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1054</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>446</td>\n",
       "      <td>342.0</td>\n",
       "      <td>1789.0</td>\n",
       "      <td>[90-99)</td>\n",
       "      <td>american</td>\n",
       "      <td>679</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2015-02-16 03:02:02+00:00</td>\n",
       "      <td>2015-02-16 03:50:19+00:00</td>\n",
       "      <td>1229</td>\n",
       "      <td>korean</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3748</td>\n",
       "      <td>2</td>\n",
       "      <td>1499</td>\n",
       "      <td>...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>251</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>2897.0</td>\n",
       "      <td>[90-99)</td>\n",
       "      <td>asian</td>\n",
       "      <td>750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-01-25 23:24:42+00:00</td>\n",
       "      <td>2015-01-25 23:59:07+00:00</td>\n",
       "      <td>6770</td>\n",
       "      <td>pizza</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>599</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>251</td>\n",
       "      <td>589.0</td>\n",
       "      <td>2065.0</td>\n",
       "      <td>[75-90)</td>\n",
       "      <td>italian</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-02-14 03:42:33+00:00</td>\n",
       "      <td>2015-02-14 04:43:18+00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>mexican</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>995</td>\n",
       "      <td>1</td>\n",
       "      <td>995</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>251</td>\n",
       "      <td>760.0</td>\n",
       "      <td>3645.0</td>\n",
       "      <td>[75-90)</td>\n",
       "      <td>mexican</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-02-01 23:06:51+00:00</td>\n",
       "      <td>2015-02-01 23:38:44+00:00</td>\n",
       "      <td>5700</td>\n",
       "      <td>sandwich</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1097</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>251</td>\n",
       "      <td>473.0</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>[90-99)</td>\n",
       "      <td>american</td>\n",
       "      <td>80</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  market_id                 created_at       actual_delivery_time  store_id  \\\n",
       "0       2.0  2015-02-17 22:10:38+00:00  2015-02-17 22:40:27+00:00      2963   \n",
       "1       4.0  2015-02-16 03:02:02+00:00  2015-02-16 03:50:19+00:00      1229   \n",
       "2       2.0  2015-01-25 23:24:42+00:00  2015-01-25 23:59:07+00:00      6770   \n",
       "3       5.0  2015-02-14 03:42:33+00:00  2015-02-14 04:43:18+00:00        15   \n",
       "4       2.0  2015-02-01 23:06:51+00:00  2015-02-01 23:38:44+00:00      5700   \n",
       "\n",
       "  store_primary_category order_protocol  total_items  subtotal  \\\n",
       "0               american            1.0            3      1054   \n",
       "1                 korean            2.0            2      3748   \n",
       "2                  pizza            3.0            2      1998   \n",
       "3                mexican            3.0            1       995   \n",
       "4               sandwich            3.0            2      1097   \n",
       "\n",
       "   num_distinct_items  min_item_price  ...  total_onshift_dashers  \\\n",
       "0                   3               0  ...                   15.0   \n",
       "1                   2            1499  ...                  109.0   \n",
       "2                   1             599  ...                   28.0   \n",
       "3                   1             995  ...                   25.0   \n",
       "4                   2             399  ...                   58.0   \n",
       "\n",
       "   total_busy_dashers  total_outstanding_orders  \\\n",
       "0                14.0                      15.0   \n",
       "1               102.0                     181.0   \n",
       "2                53.0                      46.0   \n",
       "3                25.0                      46.0   \n",
       "4                61.0                      64.0   \n",
       "\n",
       "   estimated_order_place_duration  \\\n",
       "0                             446   \n",
       "1                             251   \n",
       "2                             251   \n",
       "3                             251   \n",
       "4                             251   \n",
       "\n",
       "   estimated_store_to_consumer_driving_duration  seconds_to_delivery  \\\n",
       "0                                         342.0               1789.0   \n",
       "1                                        1012.0               2897.0   \n",
       "2                                         589.0               2065.0   \n",
       "3                                         760.0               3645.0   \n",
       "4                                         473.0               1913.0   \n",
       "\n",
       "   store_id_freq store_category_type item_price_range  hour_of_day  \n",
       "0        [90-99)            american              679           22  \n",
       "1        [90-99)               asian              750            3  \n",
       "2        [75-90)             italian                0           23  \n",
       "3        [75-90)             mexican                0            3  \n",
       "4        [90-99)            american               80           23  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_path = '../datasets/clean/train_data.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish numeric vs. categorical features, & separate features from target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = [\n",
    "    'total_items',\n",
    "    'subtotal',\n",
    "    'num_distinct_items',\n",
    "    'total_onshift_dashers',\n",
    "    'total_busy_dashers',\n",
    "    'total_outstanding_orders',\n",
    "    'estimated_order_place_duration',\n",
    "    'estimated_store_to_consumer_driving_duration',\n",
    "    'item_price_range',\n",
    "    'hour_of_day',\n",
    "]\n",
    "\n",
    "categorical_feats = [\n",
    "    'market_id',\n",
    "    'order_protocol',\n",
    "    'store_id_freq',\n",
    "    'store_category_type',\n",
    "]\n",
    "\n",
    "target = 'seconds_to_delivery'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df[numeric_feats + categorical_feats]\n",
    "\n",
    "df_y = df[target]\n",
    "\n",
    "assert len(df_X)==len(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_items</th>\n",
       "      <th>subtotal</th>\n",
       "      <th>num_distinct_items</th>\n",
       "      <th>total_onshift_dashers</th>\n",
       "      <th>total_busy_dashers</th>\n",
       "      <th>total_outstanding_orders</th>\n",
       "      <th>estimated_order_place_duration</th>\n",
       "      <th>estimated_store_to_consumer_driving_duration</th>\n",
       "      <th>item_price_range</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>market_id</th>\n",
       "      <th>order_protocol</th>\n",
       "      <th>store_id_freq</th>\n",
       "      <th>store_category_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1054</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>446</td>\n",
       "      <td>342.0</td>\n",
       "      <td>679</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[90-99)</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3748</td>\n",
       "      <td>2</td>\n",
       "      <td>109.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>251</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>750</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[90-99)</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>251</td>\n",
       "      <td>589.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[75-90)</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>995</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>251</td>\n",
       "      <td>760.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[75-90)</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1097</td>\n",
       "      <td>2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>251</td>\n",
       "      <td>473.0</td>\n",
       "      <td>80</td>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[90-99)</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_items  subtotal  num_distinct_items  total_onshift_dashers  \\\n",
       "0            3      1054                   3                   15.0   \n",
       "1            2      3748                   2                  109.0   \n",
       "2            2      1998                   1                   28.0   \n",
       "3            1       995                   1                   25.0   \n",
       "4            2      1097                   2                   58.0   \n",
       "\n",
       "   total_busy_dashers  total_outstanding_orders  \\\n",
       "0                14.0                      15.0   \n",
       "1               102.0                     181.0   \n",
       "2                53.0                      46.0   \n",
       "3                25.0                      46.0   \n",
       "4                61.0                      64.0   \n",
       "\n",
       "   estimated_order_place_duration  \\\n",
       "0                             446   \n",
       "1                             251   \n",
       "2                             251   \n",
       "3                             251   \n",
       "4                             251   \n",
       "\n",
       "   estimated_store_to_consumer_driving_duration  item_price_range  \\\n",
       "0                                         342.0               679   \n",
       "1                                        1012.0               750   \n",
       "2                                         589.0                 0   \n",
       "3                                         760.0                 0   \n",
       "4                                         473.0                80   \n",
       "\n",
       "   hour_of_day market_id order_protocol store_id_freq store_category_type  \n",
       "0           22       2.0            1.0       [90-99)            american  \n",
       "1            3       4.0            2.0       [90-99)               asian  \n",
       "2           23       2.0            3.0       [75-90)             italian  \n",
       "3            3       5.0            3.0       [75-90)             mexican  \n",
       "4           23       2.0            3.0       [90-99)            american  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1789.0\n",
       "1    2897.0\n",
       "2    2065.0\n",
       "3    3645.0\n",
       "4    1913.0\n",
       "Name: seconds_to_delivery, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Preprocessing Pipelines**\n",
    "\n",
    "Now, we'll define the transformers we want to include in our preprocessing pipeline.\n",
    "\n",
    "Scikit-learn includes many transformers out of the box that you may include in a Pipeline object to automate the preprocessing workflow prior to model prediction. Additionally, you may define your own custom transformer to apply on your data, if scikit-learn does not provide it. \n",
    "\n",
    "For our data, we will define a custom transformer to drop highly correlated features in our data prior to passing it to our model for prediction. \n",
    "- It is a stateful transformation (i.e. it must learn the correlations among our feature space prior to the transformation).\n",
    "- So, we must implement fit() & transform() methods.\n",
    "\n",
    "For more information about defining custom data transformers, check out the links at the bottom of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "import custom_transformers\n",
    "from custom_transformers import DropHighlyCorrelatedFeatures # custom transformer to drop highly correlated features prior to model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression algorithms we will experiment with will require all or a subset of the following preprocessing steps leading up to prediction:\n",
    "- Imputing missing feature values\n",
    "- Scaling feature set (for Lasso & SVR only)\n",
    "- Dropping highly correlated features\n",
    "- One-hot encoding categorical features \n",
    "\n",
    "Lasso Regression & Support Vector Regression algorithms are sensitive to scaling since they involve distance-based computations, whereas Random Forest & Gradient Boosted Trees are built on top of Decision Trees, which involve threshold based splitting. \n",
    "- So, the pipeline for Lasso & SVR will require scaling the feature space. \n",
    "- Thus, we'll define two preprocessing pipelines, one with scaling and one without.\n",
    "\n",
    "Note that we already took care of some of these preprocessing steps manually in our data preparation. However, defining this pipeline will come in handy when we want to apply this workflow to new data, as these steps will already be saved as part of our model artifact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence of transformations to apply to categorical features\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"categorical_imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", drop='first', sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# sequence of transformations to apply to numeric features\n",
    "numeric_pipeline_scaled = Pipeline(\n",
    "    steps=[\n",
    "        (\"numeric_imputer\", SimpleImputer(strategy=\"median\")), \n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"drop_correlated_feats\", DropHighlyCorrelatedFeatures()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "numeric_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"numeric_imputer\", SimpleImputer(strategy=\"median\")), \n",
    "        (\"drop_correlated_feats\", DropHighlyCorrelatedFeatures()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# combine numeric & categorical feature transformations into single ColumnTransformer() object\n",
    "preprocessor_w_scaling = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_pipeline_scaled, numeric_feats),\n",
    "        ('cat', categorical_pipeline, categorical_feats),\n",
    "    ],\n",
    ")\n",
    "\n",
    "preprocessor_wo_scaling = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_pipeline, numeric_feats),\n",
    "        ('cat', categorical_pipeline, categorical_feats),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**\n",
    "\n",
    "Models linear relationship between a scalar target and one or more explanatory variables. Lasso regularization adds a penalty term to linear regression objective function that may zero out coefficients for features with little to no relationship with the prediction target.\n",
    "\n",
    "Preprocessing requirements:\n",
    "- Scaling (fair regularization requires features to be on similar scales, and scaling may speed up the linear regression optimization process)\n",
    "- One-hot encoding for categorical features\n",
    "\n",
    "Relevant hyperparameters:\n",
    "- alpha: controls regularization strength, where larger values indicate stronger regularization\n",
    "\n",
    "Scikit-learn APIs:\n",
    "- https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso\n",
    "- https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lasso_reg = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_w_scaling), \n",
    "        (\"regression\", Lasso(random_state=13)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "lasso_param_grid = {\n",
    "    \"regression__alpha\": np.logspace(-3, -2, 10),\n",
    "}\n",
    "\n",
    "lasso_search_cv = GridSearchCV(lasso_reg, lasso_param_grid, scoring='neg_root_mean_squared_error', verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_search_cv.fit(df_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_regression__alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.856981</td>\n",
       "      <td>2.214817</td>\n",
       "      <td>0.119525</td>\n",
       "      <td>0.015137</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-1080.421798</td>\n",
       "      <td>30.231262</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.789128</td>\n",
       "      <td>2.547866</td>\n",
       "      <td>0.132451</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>0.007743</td>\n",
       "      <td>-1080.422253</td>\n",
       "      <td>30.231207</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.580545</td>\n",
       "      <td>4.298250</td>\n",
       "      <td>0.129238</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>-1080.422633</td>\n",
       "      <td>30.231133</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.344698</td>\n",
       "      <td>3.376484</td>\n",
       "      <td>0.123985</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>-1080.422885</td>\n",
       "      <td>30.231062</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.871059</td>\n",
       "      <td>2.859284</td>\n",
       "      <td>0.136542</td>\n",
       "      <td>0.016378</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>-1080.423208</td>\n",
       "      <td>30.231025</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.386101</td>\n",
       "      <td>5.593429</td>\n",
       "      <td>0.127853</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>-1080.423468</td>\n",
       "      <td>30.230995</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.773890</td>\n",
       "      <td>2.511777</td>\n",
       "      <td>0.132348</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>-1080.423675</td>\n",
       "      <td>30.230969</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.924668</td>\n",
       "      <td>3.056647</td>\n",
       "      <td>0.122591</td>\n",
       "      <td>0.032291</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>-1080.423838</td>\n",
       "      <td>30.230948</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.363257</td>\n",
       "      <td>4.356095</td>\n",
       "      <td>0.124623</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>-1080.423967</td>\n",
       "      <td>30.230931</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.701822</td>\n",
       "      <td>6.138398</td>\n",
       "      <td>0.094549</td>\n",
       "      <td>0.029439</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-1080.424068</td>\n",
       "      <td>30.230918</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9      19.856981      2.214817         0.119525        0.015137   \n",
       "8      19.789128      2.547866         0.132451        0.005560   \n",
       "7      26.580545      4.298250         0.129238        0.020896   \n",
       "6      23.344698      3.376484         0.123985        0.006741   \n",
       "5      25.871059      2.859284         0.136542        0.016378   \n",
       "4      29.386101      5.593429         0.127853        0.008373   \n",
       "3      24.773890      2.511777         0.132348        0.005810   \n",
       "2      28.924668      3.056647         0.122591        0.032291   \n",
       "1      23.363257      4.356095         0.124623        0.009060   \n",
       "0      18.701822      6.138398         0.094549        0.029439   \n",
       "\n",
       "   param_regression__alpha  mean_test_score  std_test_score  rank_test_score  \n",
       "9                 0.010000     -1080.421798       30.231262                1  \n",
       "8                 0.007743     -1080.422253       30.231207                2  \n",
       "7                 0.005995     -1080.422633       30.231133                3  \n",
       "6                 0.004642     -1080.422885       30.231062                4  \n",
       "5                 0.003594     -1080.423208       30.231025                5  \n",
       "4                 0.002783     -1080.423468       30.230995                6  \n",
       "3                 0.002154     -1080.423675       30.230969                7  \n",
       "2                 0.001668     -1080.423838       30.230948                8  \n",
       "1                 0.001292     -1080.423967       30.230931                9  \n",
       "0                 0.001000     -1080.424068       30.230918               10  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv_results_df = pd.DataFrame(lasso_search_cv.cv_results_)\n",
    "\n",
    "lasso_cv_results_df.sort_values(by='mean_test_score', ascending=False).drop(columns=['params','split0_test_score','split1_test_score','split2_test_score','split3_test_score','split4_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -1080.4217982441126\n",
      "Best Parameters: {'regression__alpha': np.float64(0.01)}\n"
     ]
    }
   ],
   "source": [
    "# Get the score of the best performing model & its alpha value\n",
    "print(\"Best Score:\", lasso_search_cv.best_score_)\n",
    "print(\"Best Parameters:\", lasso_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression results:\n",
    "- Best performing model had a root mean squared error of ~1080 seconds, or ~18 minutes. However, all models across different values of alpha had nearly identical performance. \n",
    "- On average, our predictions for delivery duration are ~18 minutes off from the true delivery duration. So, not super effective for predicting delivery duration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Regression**\n",
    "\n",
    "Regression algorithm derived from Support Vector Machines (https://scikit-learn.org/stable/modules/svm.html).\n",
    "\n",
    "Preprocessing requirements:\n",
    "- Scaling (SVR computes dot products between observations in the feature space, so certain features may dominate the dot product computations if they are on widely different scales)\n",
    "- One-hot encoding for categorical features\n",
    "\n",
    "Relevant hyperparameters:\n",
    "- C: regularization parameter\n",
    "- epsilon: error-budget (non-negative)\n",
    "- kernel: linear, poly, rbf -> The relationship between the features & target doesn't seem to be appropriately described by a linear relationship. Additionally, fitting the RBF kernel was taking extremely long, so we'll proceed with a polynomial kernel.\n",
    "\n",
    "Scikit-learn APIs:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html#sklearn.svm.LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svr_reg = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_w_scaling),\n",
    "        (\"regression\", SVR(kernel='poly', max_iter=1000)), \n",
    "    ]\n",
    ")\n",
    "\n",
    "svr_param_grid = {\n",
    "    \"regression__C\": np.logspace(-3, 1, 4),\n",
    "    'regression__epsilon': np.logspace(-3, 1, 4),\n",
    "    # # 'regression__kernel': ['linear', 'poly', 'rbf']\n",
    "\n",
    "}\n",
    "\n",
    "svr_search_cv = GridSearchCV(svr_reg, svr_param_grid, verbose=4, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_search_cv.fit(df_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_regression__C</th>\n",
       "      <th>param_regression__epsilon</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.664221</td>\n",
       "      <td>0.173374</td>\n",
       "      <td>1.374567</td>\n",
       "      <td>0.055117</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>0.464159</td>\n",
       "      <td>-1335.926884</td>\n",
       "      <td>32.070325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.401234</td>\n",
       "      <td>0.455546</td>\n",
       "      <td>1.521276</td>\n",
       "      <td>0.205808</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-1335.927035</td>\n",
       "      <td>32.070505</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.612127</td>\n",
       "      <td>0.153293</td>\n",
       "      <td>1.395525</td>\n",
       "      <td>0.046941</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>-1335.927035</td>\n",
       "      <td>32.070505</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.057626</td>\n",
       "      <td>0.261788</td>\n",
       "      <td>1.459500</td>\n",
       "      <td>0.064989</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-1336.054941</td>\n",
       "      <td>32.033936</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.964360</td>\n",
       "      <td>0.165073</td>\n",
       "      <td>3.606214</td>\n",
       "      <td>0.615819</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>-1336.430851</td>\n",
       "      <td>31.995590</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.455701</td>\n",
       "      <td>0.643504</td>\n",
       "      <td>3.920583</td>\n",
       "      <td>0.165312</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-1336.430851</td>\n",
       "      <td>31.995590</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.245808</td>\n",
       "      <td>2.374624</td>\n",
       "      <td>2.253378</td>\n",
       "      <td>0.903757</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.464159</td>\n",
       "      <td>-1336.430851</td>\n",
       "      <td>31.995590</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.947139</td>\n",
       "      <td>1.691789</td>\n",
       "      <td>1.903838</td>\n",
       "      <td>0.381740</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-1336.431349</td>\n",
       "      <td>31.995209</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.941057</td>\n",
       "      <td>0.100923</td>\n",
       "      <td>1.487249</td>\n",
       "      <td>0.073854</td>\n",
       "      <td>0.464159</td>\n",
       "      <td>0.464159</td>\n",
       "      <td>-1486.448047</td>\n",
       "      <td>279.117572</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.824838</td>\n",
       "      <td>0.350721</td>\n",
       "      <td>1.469014</td>\n",
       "      <td>0.041215</td>\n",
       "      <td>0.464159</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-1486.465942</td>\n",
       "      <td>279.112962</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.703624</td>\n",
       "      <td>0.100430</td>\n",
       "      <td>1.400247</td>\n",
       "      <td>0.055851</td>\n",
       "      <td>0.464159</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>-1486.465942</td>\n",
       "      <td>279.112962</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.741435</td>\n",
       "      <td>0.211304</td>\n",
       "      <td>1.395020</td>\n",
       "      <td>0.022209</td>\n",
       "      <td>0.464159</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-1504.615970</td>\n",
       "      <td>308.185437</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.841767</td>\n",
       "      <td>0.205398</td>\n",
       "      <td>1.411328</td>\n",
       "      <td>0.037763</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-22376.648002</td>\n",
       "      <td>6412.144580</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.024936</td>\n",
       "      <td>0.099893</td>\n",
       "      <td>1.482524</td>\n",
       "      <td>0.063390</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.464159</td>\n",
       "      <td>-22440.421704</td>\n",
       "      <td>6489.267642</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.930181</td>\n",
       "      <td>0.175856</td>\n",
       "      <td>1.449837</td>\n",
       "      <td>0.035257</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>-22450.688467</td>\n",
       "      <td>6492.971391</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.954519</td>\n",
       "      <td>0.132288</td>\n",
       "      <td>1.489024</td>\n",
       "      <td>0.030425</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-22450.688467</td>\n",
       "      <td>6492.971391</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6        9.664221      0.173374         1.374567        0.055117   \n",
       "4       10.401234      0.455546         1.521276        0.205808   \n",
       "5        9.612127      0.153293         1.395525        0.046941   \n",
       "7       10.057626      0.261788         1.459500        0.064989   \n",
       "1       23.964360      0.165073         3.606214        0.615819   \n",
       "0       23.455701      0.643504         3.920583        0.165312   \n",
       "2       13.245808      2.374624         2.253378        0.903757   \n",
       "3       12.947139      1.691789         1.903838        0.381740   \n",
       "10       9.941057      0.100923         1.487249        0.073854   \n",
       "8        9.824838      0.350721         1.469014        0.041215   \n",
       "9        9.703624      0.100430         1.400247        0.055851   \n",
       "11       9.741435      0.211304         1.395020        0.022209   \n",
       "15       9.841767      0.205398         1.411328        0.037763   \n",
       "14      10.024936      0.099893         1.482524        0.063390   \n",
       "13       9.930181      0.175856         1.449837        0.035257   \n",
       "12       9.954519      0.132288         1.489024        0.030425   \n",
       "\n",
       "    param_regression__C  param_regression__epsilon  mean_test_score  \\\n",
       "6              0.021544                   0.464159     -1335.926884   \n",
       "4              0.021544                   0.001000     -1335.927035   \n",
       "5              0.021544                   0.021544     -1335.927035   \n",
       "7              0.021544                  10.000000     -1336.054941   \n",
       "1              0.001000                   0.021544     -1336.430851   \n",
       "0              0.001000                   0.001000     -1336.430851   \n",
       "2              0.001000                   0.464159     -1336.430851   \n",
       "3              0.001000                  10.000000     -1336.431349   \n",
       "10             0.464159                   0.464159     -1486.448047   \n",
       "8              0.464159                   0.001000     -1486.465942   \n",
       "9              0.464159                   0.021544     -1486.465942   \n",
       "11             0.464159                  10.000000     -1504.615970   \n",
       "15            10.000000                  10.000000    -22376.648002   \n",
       "14            10.000000                   0.464159    -22440.421704   \n",
       "13            10.000000                   0.021544    -22450.688467   \n",
       "12            10.000000                   0.001000    -22450.688467   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "6        32.070325                1  \n",
       "4        32.070505                2  \n",
       "5        32.070505                2  \n",
       "7        32.033936                4  \n",
       "1        31.995590                5  \n",
       "0        31.995590                5  \n",
       "2        31.995590                7  \n",
       "3        31.995209                8  \n",
       "10      279.117572                9  \n",
       "8       279.112962               10  \n",
       "9       279.112962               10  \n",
       "11      308.185437               12  \n",
       "15     6412.144580               13  \n",
       "14     6489.267642               14  \n",
       "13     6492.971391               15  \n",
       "12     6492.971391               16  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_cv_results_df = pd.DataFrame(svr_search_cv.cv_results_)\n",
    "\n",
    "svr_cv_results_df.sort_values(\"mean_test_score\", ascending=False).drop(columns=['params','split0_test_score','split1_test_score','split2_test_score','split3_test_score','split4_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -1335.926883563665\n",
      "Best params: {'regression__C': np.float64(0.021544346900318832), 'regression__epsilon': np.float64(0.46415888336127775)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score:\", svr_search_cv.best_score_)\n",
    "print(\"Best params:\", svr_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR results:\n",
    "- Best performing model had a root mean squared error of ~1335 seconds, or ~22 minutes.\n",
    "- This is about 4 minutes worse than our best Lasso Regression model.\n",
    "- Tuning the epsilon parameter (error budget) had nearly 0 impact on performance. However, weaker regularization (param_regression__C) negatively impacted model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Regression**\n",
    "\n",
    "Ensemble method that combines the predictions of multiple decision trees, where each tree is built from a bootstrap sample drawn from the training set.\n",
    "\n",
    "Preprocessing requirements:\n",
    "- One-hot encode categorical features (not technically required)\n",
    "\n",
    "Relevant hyperparamaters:\n",
    "- n_estimators: # of trees in ensemble\n",
    "- max_depth: limit tree complexity (how far each tree should be split)\n",
    "- max_features: # of features to consider at each node split (lower value means trees are less correlated)\n",
    "\n",
    "Scikit-learn APIs:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "rfr_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_wo_scaling), \n",
    "        (\"regressor\", RandomForestRegressor(random_state=13))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rfr_param_grid = {\n",
    "    \"regressor__n_estimators\": [10, 100, 200],\n",
    "    # 'regressor__max_depth': [None, 50],\n",
    "    'regressor__max_features': ['sqrt', 'log2', None],\n",
    "}\n",
    "\n",
    "rfr_search_cv = GridSearchCV(rfr_clf, rfr_param_grid, verbose=4, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_search_cv.fit(df_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_regressor__max_features</th>\n",
       "      <th>param_regressor__n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88.732248</td>\n",
       "      <td>4.256260</td>\n",
       "      <td>4.498945</td>\n",
       "      <td>0.132426</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>-1049.517021</td>\n",
       "      <td>30.309714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.914489</td>\n",
       "      <td>0.523497</td>\n",
       "      <td>2.291023</td>\n",
       "      <td>0.045759</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>-1049.600568</td>\n",
       "      <td>30.367691</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.547280</td>\n",
       "      <td>4.454571</td>\n",
       "      <td>1.452601</td>\n",
       "      <td>0.282438</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>-1052.371489</td>\n",
       "      <td>30.212661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.030757</td>\n",
       "      <td>0.498581</td>\n",
       "      <td>1.247704</td>\n",
       "      <td>0.080938</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>-1052.543702</td>\n",
       "      <td>30.243942</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>420.705924</td>\n",
       "      <td>5.275555</td>\n",
       "      <td>4.731429</td>\n",
       "      <td>0.056524</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>-1068.528854</td>\n",
       "      <td>26.866791</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>212.509280</td>\n",
       "      <td>1.107555</td>\n",
       "      <td>2.450465</td>\n",
       "      <td>0.036316</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>-1071.614566</td>\n",
       "      <td>26.550061</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.278628</td>\n",
       "      <td>0.086512</td>\n",
       "      <td>0.176639</td>\n",
       "      <td>0.029473</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>-1099.737394</td>\n",
       "      <td>28.910343</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.710949</td>\n",
       "      <td>0.116275</td>\n",
       "      <td>0.161595</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>-1102.077337</td>\n",
       "      <td>29.032308</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22.083551</td>\n",
       "      <td>0.290809</td>\n",
       "      <td>0.336150</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>-1120.108579</td>\n",
       "      <td>24.608533</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5      88.732248      4.256260         4.498945        0.132426   \n",
       "2      47.914489      0.523497         2.291023        0.045759   \n",
       "4      24.547280      4.454571         1.452601        0.282438   \n",
       "1      24.030757      0.498581         1.247704        0.080938   \n",
       "8     420.705924      5.275555         4.731429        0.056524   \n",
       "7     212.509280      1.107555         2.450465        0.036316   \n",
       "3       2.278628      0.086512         0.176639        0.029473   \n",
       "0       2.710949      0.116275         0.161595        0.012457   \n",
       "6      22.083551      0.290809         0.336150        0.010065   \n",
       "\n",
       "  param_regressor__max_features  param_regressor__n_estimators  \\\n",
       "5                          log2                            200   \n",
       "2                          sqrt                            200   \n",
       "4                          log2                            100   \n",
       "1                          sqrt                            100   \n",
       "8                          None                            200   \n",
       "7                          None                            100   \n",
       "3                          log2                             10   \n",
       "0                          sqrt                             10   \n",
       "6                          None                             10   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "5     -1049.517021       30.309714                1  \n",
       "2     -1049.600568       30.367691                2  \n",
       "4     -1052.371489       30.212661                3  \n",
       "1     -1052.543702       30.243942                4  \n",
       "8     -1068.528854       26.866791                5  \n",
       "7     -1071.614566       26.550061                6  \n",
       "3     -1099.737394       28.910343                7  \n",
       "0     -1102.077337       29.032308                8  \n",
       "6     -1120.108579       24.608533                9  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_cv_results = pd.DataFrame(rfr_search_cv.cv_results_)\n",
    "rfr_cv_results = rfr_cv_results.sort_values(\"mean_test_score\", ascending=False).drop(columns=['params','split0_test_score','split1_test_score','split2_test_score','split3_test_score','split4_test_score'])\n",
    "rfr_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -1049.5170207071897\n",
      "Best params: {'regressor__max_features': 'log2', 'regressor__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score:\", rfr_search_cv.best_score_)\n",
    "print(\"Best params:\", rfr_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFR results:\n",
    "- Best performing model had a root mean squared error of ~1050 seconds (~17.5 minutes).\n",
    "- Higher decorrelation among base estimators (param_regressor__max_features) resulted in better model performance, irrespective of number of estimators involved.\n",
    "- So far, this is our best performing model, but not by much (errors are ~30 seconds lower than that of Lasso Regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosted Regression**\n",
    "\n",
    "Ensemble method that iteratively fits many weak learners in sequence, where each learner attempts to correct the errors of the previous. As opposed to random forest regression, the learners in gradient boosted regression are not independent.\n",
    "\n",
    "Preprocessing requirements:\n",
    "- One-hot encode categorical features (not technically required)\n",
    "\n",
    "Relevant hyperparameters:\n",
    "- learning_rate: dictates how much each individual learner contributes to final prediction \n",
    "- n_estimators: # of learners to include in ensemble\n",
    "\n",
    "Scikit-learn APIs:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "gbr_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor_wo_scaling), \n",
    "        (\"regressor\", GradientBoostingRegressor(random_state=13))\n",
    "    ]\n",
    ")\n",
    "\n",
    "gbr_param_grid = {\n",
    "    \"regressor__n_estimators\": [10, 100, 200],\n",
    "    'regressor__learning_rate': np.logspace(-3, 0, 4),\n",
    "}\n",
    "\n",
    "gbr_search_cv = GridSearchCV(gbr_clf, gbr_param_grid, verbose=4, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_search_cv.fit(df_X, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_regressor__learning_rate</th>\n",
       "      <th>param_regressor__n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>82.697965</td>\n",
       "      <td>0.732269</td>\n",
       "      <td>0.266115</td>\n",
       "      <td>0.018268</td>\n",
       "      <td>0.100</td>\n",
       "      <td>200</td>\n",
       "      <td>-1046.317871</td>\n",
       "      <td>30.375405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41.944485</td>\n",
       "      <td>1.204494</td>\n",
       "      <td>0.173177</td>\n",
       "      <td>0.012902</td>\n",
       "      <td>0.100</td>\n",
       "      <td>100</td>\n",
       "      <td>-1052.587940</td>\n",
       "      <td>31.119862</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42.018806</td>\n",
       "      <td>0.831958</td>\n",
       "      <td>0.163385</td>\n",
       "      <td>0.012175</td>\n",
       "      <td>1.000</td>\n",
       "      <td>100</td>\n",
       "      <td>-1055.328669</td>\n",
       "      <td>24.920510</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>83.474348</td>\n",
       "      <td>1.678366</td>\n",
       "      <td>0.222026</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>1.000</td>\n",
       "      <td>200</td>\n",
       "      <td>-1062.160108</td>\n",
       "      <td>25.026698</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.640410</td>\n",
       "      <td>0.055426</td>\n",
       "      <td>0.106112</td>\n",
       "      <td>0.017491</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10</td>\n",
       "      <td>-1062.575004</td>\n",
       "      <td>30.339912</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81.371165</td>\n",
       "      <td>3.351004</td>\n",
       "      <td>0.309590</td>\n",
       "      <td>0.012831</td>\n",
       "      <td>0.010</td>\n",
       "      <td>200</td>\n",
       "      <td>-1083.627139</td>\n",
       "      <td>31.384947</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.131966</td>\n",
       "      <td>0.323323</td>\n",
       "      <td>0.109805</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.100</td>\n",
       "      <td>10</td>\n",
       "      <td>-1102.672371</td>\n",
       "      <td>31.257071</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.838949</td>\n",
       "      <td>1.182333</td>\n",
       "      <td>0.205603</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.010</td>\n",
       "      <td>100</td>\n",
       "      <td>-1103.806387</td>\n",
       "      <td>31.095903</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.614889</td>\n",
       "      <td>1.752438</td>\n",
       "      <td>0.355836</td>\n",
       "      <td>0.025337</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>-1141.503328</td>\n",
       "      <td>30.243615</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.691835</td>\n",
       "      <td>0.123246</td>\n",
       "      <td>0.104713</td>\n",
       "      <td>0.007916</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>-1149.762269</td>\n",
       "      <td>30.028332</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.023206</td>\n",
       "      <td>0.423527</td>\n",
       "      <td>0.224596</td>\n",
       "      <td>0.019335</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>-1149.801581</td>\n",
       "      <td>30.030826</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.919006</td>\n",
       "      <td>0.112778</td>\n",
       "      <td>0.104122</td>\n",
       "      <td>0.020916</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>-1158.637289</td>\n",
       "      <td>29.815061</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8       82.697965      0.732269         0.266115        0.018268   \n",
       "7       41.944485      1.204494         0.173177        0.012902   \n",
       "10      42.018806      0.831958         0.163385        0.012175   \n",
       "11      83.474348      1.678366         0.222026        0.010757   \n",
       "9        4.640410      0.055426         0.106112        0.017491   \n",
       "5       81.371165      3.351004         0.309590        0.012831   \n",
       "6        5.131966      0.323323         0.109805        0.001289   \n",
       "4       41.838949      1.182333         0.205603        0.021186   \n",
       "2       83.614889      1.752438         0.355836        0.025337   \n",
       "3        4.691835      0.123246         0.104713        0.007916   \n",
       "1       44.023206      0.423527         0.224596        0.019335   \n",
       "0        4.919006      0.112778         0.104122        0.020916   \n",
       "\n",
       "    param_regressor__learning_rate  param_regressor__n_estimators  \\\n",
       "8                            0.100                            200   \n",
       "7                            0.100                            100   \n",
       "10                           1.000                            100   \n",
       "11                           1.000                            200   \n",
       "9                            1.000                             10   \n",
       "5                            0.010                            200   \n",
       "6                            0.100                             10   \n",
       "4                            0.010                            100   \n",
       "2                            0.001                            200   \n",
       "3                            0.010                             10   \n",
       "1                            0.001                            100   \n",
       "0                            0.001                             10   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  \n",
       "8      -1046.317871       30.375405                1  \n",
       "7      -1052.587940       31.119862                2  \n",
       "10     -1055.328669       24.920510                3  \n",
       "11     -1062.160108       25.026698                4  \n",
       "9      -1062.575004       30.339912                5  \n",
       "5      -1083.627139       31.384947                6  \n",
       "6      -1102.672371       31.257071                7  \n",
       "4      -1103.806387       31.095903                8  \n",
       "2      -1141.503328       30.243615                9  \n",
       "3      -1149.762269       30.028332               10  \n",
       "1      -1149.801581       30.030826               11  \n",
       "0      -1158.637289       29.815061               12  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_cv_results = pd.DataFrame(gbr_search_cv.cv_results_)\n",
    "gbr_cv_results = gbr_cv_results.sort_values(\"mean_test_score\", ascending=False).drop(columns=['params','split0_test_score','split1_test_score','split2_test_score','split3_test_score','split4_test_score'])\n",
    "gbr_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -1046.3178705153373\n",
      "Best params: {'regressor__learning_rate': np.float64(0.1), 'regressor__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score:\", gbr_search_cv.best_score_)\n",
    "print(\"Best params:\", gbr_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBR results:\n",
    "- Best performing model had a root mean squared error of ~1046 seconds (~17.5 minutes).\n",
    "- All models had mean errors within 120 seconds (2 minutes) of each other.\n",
    "- Best GBR model outperforms our RFR model by ~4 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison of Model Results**\n",
    "\n",
    "Let's pull the best models from each of the 4 algorithms we used and compare their scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>rmse</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>1080.421798</td>\n",
       "      <td>{'regression__alpha': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Regression</td>\n",
       "      <td>1335.926884</td>\n",
       "      <td>{'regression__C': 0.021544346900318832, 'regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1049.517021</td>\n",
       "      <td>{'regressor__max_features': 'log2', 'regressor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosted Trees</td>\n",
       "      <td>1046.317871</td>\n",
       "      <td>{'regressor__learning_rate': 0.1, 'regressor__...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   algorithm         rmse  \\\n",
       "0                      Lasso  1080.421798   \n",
       "1  Support Vector Regression  1335.926884   \n",
       "2              Random Forest  1049.517021   \n",
       "3     Gradient Boosted Trees  1046.317871   \n",
       "\n",
       "                                          parameters  \n",
       "0                        {'regression__alpha': 0.01}  \n",
       "1  {'regression__C': 0.021544346900318832, 'regre...  \n",
       "2  {'regressor__max_features': 'log2', 'regressor...  \n",
       "3  {'regressor__learning_rate': 0.1, 'regressor__...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.Series(\n",
    "    [\n",
    "        'Lasso',\n",
    "        'Support Vector Regression',\n",
    "        'Random Forest',\n",
    "        'Gradient Boosted Trees'\n",
    "    ],\n",
    "    name = 'Algorithm'\n",
    ")\n",
    "\n",
    "scores = pd.Series(\n",
    "    [\n",
    "        lasso_search_cv.best_score_,\n",
    "        svr_search_cv.best_score_,\n",
    "        rfr_search_cv.best_score_,\n",
    "        gbr_search_cv.best_score_,\n",
    "    ],\n",
    "    name = 'Scores'\n",
    ") * (-1) # make it non-negative\n",
    "\n",
    "parameters = pd.Series(\n",
    "    [\n",
    "        lasso_search_cv.best_params_,\n",
    "        svr_search_cv.best_params_,\n",
    "        rfr_search_cv.best_params_,\n",
    "        gbr_search_cv.best_params_,\n",
    "    ],\n",
    "    name = 'Parameters'\n",
    ")\n",
    "\n",
    "modeling_results = pd.DataFrame({'algorithm': models, 'rmse': scores, 'parameters': parameters})\n",
    "\n",
    "modeling_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "ax = sns.barplot(modeling_results, y=\"algorithm\", x=\"rmse\")\n",
    "\n",
    "# Add values to the bars\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, label_type='center')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result summary:\n",
    "- GBR model was the \"best\" model (lowest RMSE).\n",
    "- However, besides SVR, all models had comparable performance. RMSEs between Lasso, RFR, & GBR were all within 40 seconds of each other, and considering the prediction errors were already > 17 minutes off on average, this doesn't seem like much.\n",
    "- We'll proceed with RFR: practically, it achieved identical performance with GFR, and it has less of a tendency to overfit since each tree in the forest is built independently. Additionally, the weak correlations (r < 0.2) we saw between the features & delivery duration in our EDA may suggest that the nature of the relationship between the features & target is probably best described in a non-linear fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out hyperparameter-tuned GBR model artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved to 'best_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib  # Use joblib for efficient model serialization\n",
    "\n",
    "# Save the best model\n",
    "best_algorithm = modeling_results.sort_values(by='rmse', ascending=True)['algorithm'].iloc[0]\n",
    "\n",
    "best_grid_search = None\n",
    "match best_algorithm:\n",
    "    case best_algorithm if best_algorithm == 'Lasso':\n",
    "        best_grid_search = lasso_search_cv\n",
    "    case best_algorithm if best_algorithm == 'Support Vector Regression':\n",
    "        best_grid_search = svr_search_cv\n",
    "    case best_algorithm if best_algorithm == 'Random Forest':\n",
    "        best_grid_search = rfr_search_cv\n",
    "    case _:\n",
    "        best_grid_search = gbr_search_cv\n",
    "\n",
    "joblib.dump(best_grid_search.best_estimator_, '../models/best_model.pkl')\n",
    "print(\"Best model saved to 'best_model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "- Creating custom data transformers:\n",
    "    - https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer.html#sphx-glr-auto-examples-compose-plot-column-transformer-py\n",
    "    - https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "- Pipeline:\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "- Model scoring:\n",
    "    - https://scikit-learn.org/1.6/modules/model_evaluation.html#scoring-parameter\n",
    "    - https://datascience.stackexchange.com/questions/93531/neg-mean-squared-error-in-cross-val-score\n",
    "- Hyperparameter tuning\n",
    "    - https://scikit-learn.org/1.6/modules/grid_search.html#grid-search\n",
    "    - https://www.kaggle.com/code/kenjee/exhaustive-regression-parameter-tuning#ML-Algorithms---Regression-Example\n",
    "    - https://www.reddit.com/r/datascience/comments/mwl2zj/do_you_often_find_hyperparam_tuning_does_very/\n",
    "    - https://www.linkedin.com/advice/3/when-should-you-stop-tuning-your-hyperparameters-8j9pf#:~:text=Hyperparameter%20tuning%20is%20essential%20for,you're%20willing%20to%20spend.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
